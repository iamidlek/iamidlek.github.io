---
title: crawling-task-1
author: YHole
date: 2021-10-06 +0900
categories: [Front end, python]
tags: [python, crawling, flask]
---

## flask로 웹 만들기

### main.py

```python
from flask import Flask, render_template, request, redirect, send_file

# 만든 부분 불러오기
from scrapper import get_jobs
from exporter import save_to_file

app = Flask("SuperScrapper")

db = {}

@app.route("/")
def home():
  return render_template("potato.html")

@app.route("/report")
def report():
  word = request.args.get('word')
  if word:
    word = word.lower()
    existingJobs = db.get(word)
    if existingJobs:
      jobs = existingJobs
    else:
      jobs = get_jobs(word)
      db[word] = jobs
  else:
    return redirect("/")
  return render_template(
    "report.html",
    searchingBy=word,
    resultsNumber=len(jobs),
    jobs=jobs
  )

@app.route("/export")
def export():
  try:
    word = request.args.get('word')
    if not word:
      raise Exception()
    word = word.lower()
    jobs = db.get(word)
    if not jobs:
      raise Exception()
    save_to_file(jobs)
    return send_file('jobs.csv')
  except:
    return redirect("/")

app.run(host="0.0.0.0")  
```

### /templates

- potato.html

```html
<!DOCTYPE html>
  <html>
    <head>
    <title>Job Search</title>
  </head>
  <body>
    <h1>Job Search</h1>
    <form action="/report" method="get">
      <input placeholder='Search for a job' required name="word">
      <button>Search</button>
    </form>
  </body>
</html>
```

- report.html

```html
<!DOCTYPE html>
<html>
  <head>
    <title>Job Search</title>
    <style>
        section {
          display:grid;
          gap:20px;
          grid-template-columns: repeat(4, 1fr);
        }
    </style>
  </head>
  <body>
    <h1>Search Resuls</h1>
    <h3>Found {{resultsNumber}} results for: {{searchingBy}}</h3>
    <a href="/export?word={{searchingBy}}">Export to CSV</a>
    <section>
      <h4>Title</h4>
      <h4>Company</h4>
      <h4>Location</h4>
      <h4>Link</h4>
      {% for potato in jobs %}
        <span>{{potato.title}}</span>
        <span>{{potato.company}}</span>
        <span>{{potato.location}}</span>
        <a href="{{potato.link}}" target="_blank">Apply</a>
      {% endfor %}
    <section>
  </body>
</html>
```

### exporter.py

```python
import csv

def save_to_file(jobs):
  file = open("jobs.csv", mode="w")
  writer = csv.writer(file)
  writer.writerow(["Title", "Company", "Location", "Link"])
  for job in jobs:
    writer.writerow(list(job.values()))
  return
```

### scrapper.py

```python
import requests
from bs4 import BeautifulSoup

def get_last_page(url):
    result = requests.get(url)
    soup = BeautifulSoup(result.text, "html.parser")
    pages = soup.find("div", {"class": "s-pagination"}).find_all("a")
    last_page = pages[-2].get_text(strip=True)
    return int(last_page)


def extract_job(html):
    title = html.find("h2").find("a")["title"]
    company, location = html.find("h3").find_all(
        "span", recursive=False)
    company = company.get_text(strip=True)
    location = location.get_text(
        strip=True).strip("-").strip(" \r").strip("\n")
    job_id = html['data-jobid']
    return {
        'title': title,
        'company': company,
        'location': location,
        "apply_link": f"https://stackoverflow.com/jobs/{job_id}"
    }


def extract_jobs(last_page, url):
    jobs = []
    for page in range(last_page):
        print(f"Scrapping SO: Page: {page}")
        result = requests.get(f"{url}&pg={page+1}")
        soup = BeautifulSoup(result.text, "html.parser")
        results = soup.find_all("div", {"class": "-job"})
        for result in results:
            job = extract_job(result)
            jobs.append(job)
    return jobs


def get_jobs(word):
    url = f"https://stackoverflow.com/jobs?q={word}&sort=i"
    last_page = get_last_page(url)
    jobs = extract_jobs(last_page, url)
    return jobs
```

### 메모

- flask
  ```python
    # return render_template("bbb.html", cc = word)
    # html 쪽에선 {{ cc }} 로 사용하면 값 가져다 사용 가능
  ```
